# ä¿®å¤è®°å½•ï¼šæ•°æ®æ³„éœ²é—®é¢˜ï¼ˆLook-ahead Biasï¼‰

## é—®é¢˜æè¿°

åœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ’åºæ¨¡å‹æ—¶ï¼Œå‘ç° `data/daily_scans/` ç›®å½•ä¸‹çš„å†å²å€™é€‰æ‰«ææ–‡ä»¶å­˜åœ¨ä¸¥é‡çš„**æ•°æ®æ³„éœ²ï¼ˆLook-ahead Biasï¼‰**é—®é¢˜ï¼š

### é—®é¢˜è¡¨ç°
```csv
# candidates_20251025.csv (ç”Ÿæˆäº 2025-11-21)
symbol,base,timestamp,quote_volume,market_cap,funding_rate,ema10,ema20,ema30,atr14,latest_close,as_of
G/USDT:USDT,G,2025-11-21 00:00:00+00:00,1603722.978215,,1.551e-05,0.005613,0.006010,0.006415,0.000429,0.005372,2025-10-25
```

**é—®é¢˜ç‚¹**ï¼š
- `timestamp` åˆ—æ˜¾ç¤º `2025-11-21`ï¼ˆä»Šå¤©ï¼‰
- `as_of` åˆ—æ˜¾ç¤º `2025-10-25`ï¼ˆæ­£ç¡®çš„ä¿¡å·æ—¥æœŸï¼‰
- è¿™æ„å‘³ç€åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹çœ‹åˆ°çš„æ˜¯"æœªæ¥"çš„æ—¶é—´æˆ³ä¿¡æ¯

### æ ¹æœ¬åŸå› 

1. **`build_candidates()` å‡½æ•°**ï¼š
   - è°ƒç”¨ `fetch_bulk_history()` æ—¶æ²¡æœ‰æŒ‡å®šæˆªæ­¢æ—¥æœŸ
   - å¯¼è‡´æ€»æ˜¯è·å–æœ€æ–°çš„Kçº¿æ•°æ®
   - `timestamp` ä½¿ç”¨äº†æœ€æ–°Kçº¿çš„æ—¶é—´æˆ³è€Œä¸æ˜¯ä¿¡å·æ—¥æœŸ

2. **`run_scan()` å‡½æ•°**ï¼š
   - `fetch_24h_tickers()` æ€»æ˜¯è·å–å½“å‰æ—¶åˆ»çš„æœ€æ–°tickeræ•°æ®
   - `quote_volume` å’Œ `market_cap` ä¹Ÿæ˜¯ä»Šå¤©çš„æ•°æ®

3. **`latest_kdj_j_above_threshold()` å‡½æ•°**ï¼š
   - ä½¿ç”¨ `datetime.now()` ä½œä¸ºç»“æŸæ—¶é—´
   - æ²¡æœ‰æˆªæ­¢åˆ°å†å²çš„ `as_of_date`

---

## ä¿®å¤æ–¹æ¡ˆ

### 1. ä¿®å¤ `build_candidates()` å‡½æ•°

**æ–‡ä»¶**: [scripts/daily_candidate_scan.py](scripts/daily_candidate_scan.py)

**ä¿®æ”¹å†…å®¹**ï¼š
```python
def build_candidates(
    fetcher: BinanceDataFetcher,
    symbols: Iterable[str],
    meta_map: Dict[str, SymbolMetadata],
    *,
    timeframe: str,
    funding_cooldown: float,
    as_of_date: date,  # æ–°å¢å‚æ•°
) -> List[Candidate]:
    """
    æ„å»ºå€™é€‰åˆ—è¡¨ï¼Œä½¿ç”¨æˆªæ­¢åˆ° as_of_date çš„å†å²æ•°æ®ã€‚
    é‡è¦ï¼šä¸ºé¿å…æ•°æ®æ³„éœ²ï¼Œåªä½¿ç”¨ as_of_date åŠä¹‹å‰çš„æ•°æ®ã€‚
    """
    # è·å–å†å²æ•°æ®ï¼Œæˆªæ­¢åˆ° as_of_date
    end_dt = datetime.combine(as_of_date, datetime.max.time(), tzinfo=timezone.utc)
    start_dt = end_dt - timedelta(days=200)

    histories = fetcher.fetch_bulk_history(
        symbols,
        start=start_dt,
        end=end_dt,  # æ˜ç¡®æŒ‡å®šæˆªæ­¢æ—¥æœŸ
        timeframe=timeframe
    )

    for symbol, history in histories.items():
        # åªä¿ç•™ <= as_of_date çš„æ•°æ®
        history = history[history["timestamp"].dt.date <= as_of_date].copy()

        # ... å…¶ä½™é€»è¾‘

        # ä½¿ç”¨ as_of_date ä½œä¸ºä¿¡å·æ—¶é—´æˆ³
        signal_timestamp = pd.Timestamp(as_of_date, tz=timezone.utc)

        rows.append(
            Candidate(
                symbol=symbol,
                timestamp=signal_timestamp,  # ä½¿ç”¨ä¿¡å·æ—¥æœŸ
                # ...
            )
        )
```

### 2. ä¿®å¤ `latest_kdj_j_above_threshold()` å‡½æ•°

**ä¿®æ”¹å†…å®¹**ï¼š
```python
def latest_kdj_j_above_threshold(
    fetcher: BinanceDataFetcher,
    symbol: str,
    *,
    threshold: float = 90.0,
    hours_lookback: int = 72,
    as_of_date: Optional[date] = None,  # æ–°å¢å‚æ•°
) -> bool:
    """
    å¦‚æœæŒ‡å®š as_of_dateï¼Œåˆ™åªä½¿ç”¨è¯¥æ—¥æœŸåŠä¹‹å‰çš„æ•°æ®ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰ã€‚
    """
    if as_of_date is not None:
        # å†å²æ¨¡å¼ï¼šæˆªæ­¢åˆ° as_of_date ç»“æŸ
        end = datetime.combine(as_of_date, datetime.max.time(), tzinfo=timezone.utc)
    else:
        # å®æ—¶æ¨¡å¼ï¼šä½¿ç”¨å½“å‰æ—¶é—´
        end = datetime.now(timezone.utc)

    start = end - timedelta(hours=hours_lookback)
    frame = fetcher.fetch_klines(symbol, start=start, end=end, timeframe="1h")

    # å¦‚æœæŒ‡å®šäº† as_of_dateï¼Œå†æ¬¡è¿‡æ»¤ç¡®ä¿ä¸ä½¿ç”¨æœªæ¥æ•°æ®
    if as_of_date is not None:
        frame = frame[frame["timestamp"].dt.date <= as_of_date]

    # ... è®¡ç®— KDJ
```

### 3. æ›´æ–° `data_builder.py`

**æ–‡ä»¶**: [scripts/modeling/data_builder.py](scripts/modeling/data_builder.py)

**ä¿®æ”¹å†…å®¹**ï¼š
```python
def parse_signal_file(path: Path) -> Tuple[date, pd.DataFrame]:
    """
    è§£æå€™é€‰æ‰«ææ–‡ä»¶ï¼Œè¿”å›ä¿¡å·æ—¥æœŸå’Œå€™é€‰DataFrameã€‚

    æ³¨æ„ï¼šä½¿ç”¨æ–‡ä»¶åä¸­çš„æ—¥æœŸä½œä¸ºä¿¡å·æ—¥æœŸï¼Œè€Œä¸æ˜¯CSVä¸­çš„timestampåˆ—ï¼Œ
    å› ä¸ºtimestampå¯èƒ½åŒ…å«æ•°æ®æ³„éœ²ã€‚
    """
    as_of_str = path.stem.split("_")[1]
    as_of_date = datetime.strptime(as_of_str, "%Y%m%d").date()
    df = pd.read_csv(path)

    # éªŒè¯ as_of å­—æ®µä¸æ–‡ä»¶åä¸€è‡´
    if "as_of" in df.columns and not df.empty:
        csv_date = pd.to_datetime(df["as_of"].iloc[0]).date()
        if csv_date != as_of_date:
            logger.warning(
                f"æ–‡ä»¶ {path.name} ä¸­çš„ as_of ({csv_date}) ä¸æ–‡ä»¶åæ—¥æœŸ ({as_of_date}) ä¸ä¸€è‡´"
            )

    return as_of_date, df
```

---

## å¦‚ä½•é‡æ–°ç”Ÿæˆå†å²æ•°æ®

### æ–¹æ³•1ï¼šä½¿ç”¨æ‰¹é‡é‡æ–°ç”Ÿæˆè„šæœ¬

```bash
# é‡æ–°ç”ŸæˆæŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ‰«ææ•°æ®
python scripts/regenerate_historical_scans.py \
  --start 2025-01-01 \
  --end 2025-11-20 \
  --bottom-n 80 \
  --skip-existing  # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
```

### æ–¹æ³•2ï¼šæ‰‹åŠ¨é€æ—¥ç”Ÿæˆ

```bash
# å•ç‹¬é‡æ–°ç”ŸæˆæŸä¸€å¤©çš„æ•°æ®
python scripts/daily_candidate_scan.py --as-of 2025-10-25 --bottom-n 80
```

---

## éªŒè¯ä¿®å¤

### 1. æ£€æŸ¥ä¿®å¤åçš„æ–‡ä»¶

```bash
# æŸ¥çœ‹ä¿®å¤åçš„å€™é€‰æ–‡ä»¶
head -2 data/daily_scans/candidates_20251025.csv
```

**æœŸæœ›è¾“å‡º**ï¼š
```csv
symbol,base,timestamp,quote_volume,market_cap,funding_rate,ema10,ema20,ema30,atr14,latest_close,as_of
SLP/USDT:USDT,SLP,2025-10-25 00:00:00+00:00,1243796.479696,,5e-05,0.001242,0.001323,0.001394,0.000121,0.001217,2025-10-25
```

âœ… **`timestamp` å’Œ `as_of` éƒ½æ˜¯ `2025-10-25`**

### 2. é‡æ–°è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨ä¿®å¤åçš„æ•°æ®é‡æ–°è®­ç»ƒæ’åºæ¨¡å‹
python scripts/modeling/train_ranker.py \
  --candidates-dir data/daily_scans \
  --backtest-csv data/backtest_trades.csv \
  --daily-dir data/daily_klines \
  --hourly-dir data/hourly_klines \
  --output-dir models
```

---

## å½±å“èŒƒå›´

### âœ… å·²ä¿®å¤
- [x] `daily_candidate_scan.py` - å†å²æ‰«ææ—¶ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´æˆªæ­¢ç‚¹
- [x] `data_builder.py` - è®­ç»ƒæ•°æ®æ„å»ºæ—¶ä½¿ç”¨æ–‡ä»¶åæ—¥æœŸ
- [x] `regenerate_historical_scans.py` - æ–°å¢æ‰¹é‡é‡æ–°ç”Ÿæˆè„šæœ¬

### âš ï¸ éœ€è¦æ³¨æ„
- å†å²çš„ **èµ„é‡‘è´¹ç‡ï¼ˆfunding_rateï¼‰** ä»ç„¶ä½¿ç”¨å½“å‰æŸ¥è¯¢çš„å€¼
  - åŸå› ï¼šBinance API ä¸æä¾›å†å²èµ„é‡‘è´¹ç‡æŸ¥è¯¢æ¥å£
  - å½±å“ï¼šè¾ƒå°ï¼Œå› ä¸ºèµ„é‡‘è´¹ç‡å˜åŒ–ç›¸å¯¹ç¼“æ…¢
  - å»ºè®®ï¼šå¦‚éœ€æ›´ç²¾ç¡®ï¼Œå¯ä»å¤–éƒ¨æ•°æ®æºè¡¥å……å†å²è´¹ç‡

### ğŸ“ åç»­å»ºè®®
1. é‡æ–°ç”Ÿæˆæ‰€æœ‰å†å²æ‰«ææ–‡ä»¶ï¼ˆ`2025-01-01` è‡³ `2025-11-20`ï¼‰
2. é‡æ–°è¿è¡Œå›æµ‹éªŒè¯ä¸€è‡´æ€§
3. é‡æ–°è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹
4. å¯¹æ¯”ä¿®å¤å‰åçš„æ¨¡å‹æ€§èƒ½å·®å¼‚

---

## å…³é”®æ”¶è·

### æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ çš„é»„é‡‘æ³•åˆ™
> **æ°¸è¿œä¸è¦ä½¿ç”¨æœªæ¥ä¿¡æ¯æ¥é¢„æµ‹è¿‡å»**

åœ¨æ„å»ºé‡‘èæ—¶é—´åºåˆ—æ¨¡å‹æ—¶ï¼Œå¿…é¡»ç¡®ä¿ï¼š
1. ç‰¹å¾æå–åªä½¿ç”¨ `t` æ—¶åˆ»åŠä¹‹å‰çš„æ•°æ®
2. æ ‡ç­¾ï¼ˆlabelï¼‰å¯¹åº” `t+1` æˆ–æ›´æ™šæ—¶åˆ»çš„ç»“æœ
3. æ•°æ®åˆ‡åˆ†å¿…é¡»æŒ‰æ—¶é—´é¡ºåºï¼ˆtrain/val/test split by dateï¼‰
4. å›æµ‹æ—¶ä¸¥æ ¼æ¨¡æ‹ŸçœŸå®äº¤æ˜“åœºæ™¯ï¼ˆæ—¶é—´å»¶è¿Ÿã€æ»‘ç‚¹ã€æ‰‹ç»­è´¹ï¼‰

---

**ä¿®å¤æ—¥æœŸ**: 2025-11-21
**ä¿®å¤è€…**: Claude Code
**å½±å“ç‰ˆæœ¬**: v0.1.0+
