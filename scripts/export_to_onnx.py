# ä½é…ECSéƒ¨ç½²æŒ‡å— (2C1G)

## é—®é¢˜åˆ†æ

ä½ çš„ECSé…ç½®ï¼š
- CPU: 2æ ¸ âœ“
- å†…å­˜: 1GB âš ï¸
- æ— PyTorch âœ—

æŒ‘æˆ˜ï¼š
1. å†…å­˜ç´§å¼ ï¼ˆæ¨¡å‹è®­ç»ƒéœ€è¦1-1.5GBï¼‰
2. æ²¡æœ‰PyTorchç¯å¢ƒ
3. èµ„æºæœ‰é™ï¼Œæ— æ³•åŒæ—¶è¿è¡Œå¤šä¸ªè¿›ç¨‹

---

## ğŸ’¡ æ¨èæ–¹æ¡ˆï¼šè®­ç»ƒ-æ¨ç†åˆ†ç¦»æ¶æ„

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        æœ¬åœ°å¼€å‘æœº / é«˜é…äº‘ä¸»æœº     â”‚
â”‚        (ç”¨äºæ¨¡å‹è®­ç»ƒ)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - è®­ç»ƒåˆå§‹æ¨¡å‹                    â”‚
â”‚ - æŒç»­å­¦ä¹ æ›´æ–°                    â”‚
â”‚ - æ•°æ®æ¸…æ´—ä¸åˆ†æ                  â”‚
â”‚ - å¯ç”¨GPUåŠ é€Ÿ                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ ä¸Šä¼ è®­ç»ƒå¥½çš„æ¨¡å‹
             â”‚ rank_model.pt (20MB)
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ECS æœåŠ¡å™¨ (2C1G)          â”‚
â”‚        (ä»…è¿è¡Œæ¨ç†å’Œäº¤æ˜“)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - åŠ è½½é¢„è®­ç»ƒæ¨¡å‹                  â”‚
â”‚ - å€™é€‰æ ‡çš„æ‰“åˆ†ï¼ˆæ¨ç†ï¼‰            â”‚
â”‚ - æ‰§è¡Œäº¤æ˜“ï¼ˆå¼€ä»“/å¹³ä»“ï¼‰           â”‚
â”‚ - è®°å½•äº¤æ˜“æ•°æ®                    â”‚
â”‚ - ä¸‹è½½æ–°æ•°æ®ä¾›æœ¬åœ°è®­ç»ƒ            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤1: æœ¬åœ°ç¯å¢ƒï¼ˆè®­ç»ƒï¼‰

**åœ¨ä½ çš„æœ¬åœ°Windowsæœºå™¨ä¸Š**:

```bash
# 1. ç¡®ä¿å·²å®‰è£…å®Œæ•´ç¯å¢ƒ
pip install torch pandas numpy

# 2. è®­ç»ƒæ¨¡å‹
python -m scripts.modeling.train_ranker --epochs 50

# 3. éªŒè¯æ¨¡å‹æ–‡ä»¶
ls models/
# åº”è¯¥çœ‹åˆ°:
#   rank_model.pt          (20MBå·¦å³)
#   rank_model_meta.json   (5KB)
```

### æ­¥éª¤2: ECSç¯å¢ƒï¼ˆä»…æ¨ç†ï¼‰

**é€‰é¡¹A: ä½¿ç”¨PyTorchï¼ˆç®€å•ä½†å å†…å­˜ï¼‰**

```bash
# å®‰è£…æœ€å°PyTorchï¼ˆä»…CPUç‰ˆæœ¬ï¼‰
pip3 install torch --index-url https://download.pytorch.org/whl/cpu

# æˆ–ä½¿ç”¨å›½å†…é•œåƒ
pip3 install torch -i https://mirrors.aliyun.com/pypi/simple/ --index-url https://download.pytorch.org/whl/cpu

# å®‰è£…ä¾èµ–
pip3 install pandas numpy
```

**é€‰é¡¹B: ä½¿ç”¨ONNXï¼ˆæ›´ä¼˜ï¼Œçœå†…å­˜ï¼‰**

```bash
# å®‰è£…ONNX Runtimeï¼ˆæ¯”PyTorchå°å¾ˆå¤šï¼‰
pip3 install onnxruntime

# åœ¨æœ¬åœ°å¯¼å‡ºONNXæ¨¡å‹
python scripts/export_to_onnx.py

# ä¸Šä¼  rank_model.onnx åˆ°ECS
```

### æ­¥éª¤3: ä¸Šä¼ æ¨¡å‹åˆ°ECS

```bash
# æ–¹æ³•1: scpä¸Šä¼ 
scp models/rank_model.pt user@your-ecs-ip:~/Quant4Little/models/
scp models/rank_model_meta.json user@your-ecs-ip:~/Quant4Little/models/

# æ–¹æ³•2: rsyncåŒæ­¥
rsync -avz models/ user@your-ecs-ip:~/Quant4Little/models/

# æ–¹æ³•3: Gitï¼ˆæ¨èï¼Œå¦‚æœæ¨¡å‹ä¸å¤ªå¤§ï¼‰
git add models/
git commit -m "Update model"
git push

# åœ¨ECSä¸Š
git pull
```

---

## ğŸš€ ECSä¸Šçš„è¿è¡Œæ¨¡å¼

### æ¨¡å¼1: çº¯äº¤æ˜“ï¼ˆä¸å«æ¨¡å‹ï¼‰

**å†…å­˜éœ€æ±‚: ~150MB**

```bash
# è¿è¡ŒåŸæœ‰çš„sim_trader.pyï¼ˆä¸ä½¿ç”¨æ¨¡å‹ï¼‰
python scripts/sim_trader.py

# ä¼˜ç‚¹ï¼š
# - å†…å­˜å ç”¨å°
# - ä¸éœ€è¦PyTorch
# - è¿è¡Œç¨³å®š

# ç¼ºç‚¹ï¼š
# - æ²¡æœ‰æ¨¡å‹è¾…åŠ©é€‰è‚¡
```

### æ¨¡å¼2: æ¨¡å‹è¾…åŠ©äº¤æ˜“ï¼ˆè½»é‡çº§ï¼‰

**å†…å­˜éœ€æ±‚: ~400-500MB**

```bash
# ä½¿ç”¨è½»é‡çº§æ¨ç†å™¨
python scripts/lightweight_ranker.py  # æµ‹è¯•

# é›†æˆåˆ°äº¤æ˜“ç³»ç»Ÿ
# ä¿®æ”¹ sim_trader.py ä½¿ç”¨ LightweightRanker
```

**ä¼˜åŒ–æŠ€å·§**:

```python
# åœ¨ sim_trader.py ä¸­
from scripts.lightweight_ranker import LightweightRanker

class Trader:
    def __init__(self):
        # å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ˆéœ€è¦æ—¶æ‰åŠ è½½ï¼‰
        self.ranker = None

    def rank_candidates(self, candidates):
        # åªåœ¨éœ€è¦æ—¶åŠ è½½
        if self.ranker is None:
            self.ranker = LightweightRanker()

        # ä½¿ç”¨æ¨¡å‹æ‰“åˆ†
        scores = []
        for candidate in candidates:
            features = self.prepare_features(candidate)
            score, cls, probs = self.ranker.predict(*features)
            scores.append(score)

        # ç«‹å³é‡Šæ”¾ä¸ç”¨çš„æ•°æ®
        del features

        return scores
```

### æ¨¡å¼3: å®šæ—¶ä»»åŠ¡æ¨¡å¼

**æœ€çœèµ„æºçš„æ–¹å¼**:

```bash
# æ¯å¤©åªè¿è¡Œä¸€æ¬¡æ¨¡å‹æ¨ç†ï¼Œå…¶ä½™æ—¶é—´è¿è¡Œäº¤æ˜“
# crontab -e

# æ¯å¤©æ—©ä¸Š8ç‚¹è¿è¡Œæ¨¡å‹æ‰“åˆ†ï¼Œä¿å­˜ç»“æœ
0 8 * * * cd ~/Quant4Little && python scripts/daily_rank.py > logs/rank.log 2>&1

# æ¯åˆ†é’Ÿæ£€æŸ¥äº¤æ˜“ä¿¡å·ï¼ˆä¸åŠ è½½æ¨¡å‹ï¼‰
* * * * * cd ~/Quant4Little && python scripts/check_signals.py
```

---

## ğŸ’¾ å†…å­˜ä¼˜åŒ–æŠ€å·§

### 1. å‡å°PyTorchå†…å­˜å ç”¨

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1

# åœ¨Pythonä¸­
import torch
torch.set_num_threads(1)
```

### 2. ä½¿ç”¨Swapï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰

```bash
# å¢åŠ 1GB Swapï¼ˆåº”æ€¥ç”¨ï¼‰
sudo fallocate -l 1G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# æŸ¥çœ‹Swap
free -h
```

**æ³¨æ„**: Swapä¼šç”¨ç¡¬ç›˜ç©ºé—´ï¼Œé€Ÿåº¦æ…¢ï¼Œä¸å»ºè®®é•¿æœŸä½¿ç”¨

### 3. ç›‘æ§å†…å­˜ä½¿ç”¨

```bash
# å®æ—¶ç›‘æ§
watch -n 1 'free -h && ps aux --sort=-%mem | head -10'

# åœ¨Pythonä¸­ç›‘æ§
import psutil
process = psutil.Process()
print(f"å†…å­˜ä½¿ç”¨: {process.memory_info().rss / 1024**2:.1f} MB")
```

---

## ğŸ“¦ ä¸åŒæ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | å†…å­˜éœ€æ±‚ | CPUéœ€æ±‚ | éœ€è¦PyTorch | æ¨èåº¦ |
|------|---------|---------|------------|--------|
| çº¯äº¤æ˜“ï¼ˆæ— æ¨¡å‹ï¼‰ | 150MB | ä½ | âœ— | â­â­â­ |
| è½»é‡çº§æ¨ç† | 400MB | ä¸­ | âœ“ | â­â­â­â­ |
| å®Œæ•´ç³»ç»Ÿï¼ˆå«è®­ç»ƒï¼‰ | 1.5GB | é«˜ | âœ“ | âœ— ä¸é€‚åˆ |
| å®šæ—¶ä»»åŠ¡æ¨¡å¼ | 200MB | ä½ | âœ— | â­â­â­â­â­ |
| ONNXæ¨ç† | 250MB | ä½ | âœ— | â­â­â­â­â­ |

---

## ğŸ¯ æ¨èé…ç½®æ–¹æ¡ˆ

### æ–¹æ¡ˆA: æœ€ç®€å•ï¼ˆé€‚åˆå¿«é€Ÿä¸Šæ‰‹ï¼‰

```
æœ¬åœ°: è®­ç»ƒæ¨¡å‹
ECS: è¿è¡ŒåŸæœ‰äº¤æ˜“ç­–ç•¥ï¼ˆä¸ç”¨æ¨¡å‹ï¼‰

ä¼˜ç‚¹ï¼š
- ç¨³å®šå¯é 
- å†…å­˜å……è¶³
- ä¸éœ€è¦æ”¹ä»£ç 

ç¼ºç‚¹ï¼š
- æ²¡æœ‰æ¨¡å‹ä¼˜åŒ–
```

### æ–¹æ¡ˆB: å¹³è¡¡æ–¹æ¡ˆï¼ˆæ¨èï¼‰

```
æœ¬åœ°: è®­ç»ƒæ¨¡å‹
ECS:
  1. æ¯å¤©å®šæ—¶è¿è¡Œæ¨¡å‹æ‰“åˆ†ï¼ˆ8:00ï¼‰
  2. ä¿å­˜æ‰“åˆ†ç»“æœåˆ°CSV
  3. äº¤æ˜“ç¨‹åºè¯»å–CSVé€‰è‚¡
  4. ä¸å¸¸é©»åŠ è½½æ¨¡å‹

ä¼˜ç‚¹ï¼š
- æœ‰æ¨¡å‹è¾…åŠ©
- å†…å­˜å ç”¨å°
- æ€§èƒ½å¥½

å®ç°ï¼š
```

åˆ›å»ºå®šæ—¶æ‰“åˆ†è„šæœ¬ `scripts/daily_rank.py`:

```python
#!/usr/bin/env python3
"""
æ¯æ—¥å®šæ—¶æ¨¡å‹æ‰“åˆ†
è¿è¡Œåç«‹å³é€€å‡ºï¼Œä¸å¸¸é©»å†…å­˜
"""
from scripts.lightweight_ranker import LightweightRanker
import pandas as pd
from pathlib import Path
from datetime import datetime

def main():
    # åŠ è½½æ¨¡å‹
    ranker = LightweightRanker()

    # è¯»å–ä»Šæ—¥å€™é€‰
    today = datetime.now().strftime("%Y%m%d")
    candidates = pd.read_csv(f"data/daily_scans/candidates_{today}.csv")

    # æ‰“åˆ†
    scores = []
    for _, row in candidates.iterrows():
        # å‡†å¤‡ç‰¹å¾
        features = prepare_features(row)  # ä½ çš„ç‰¹å¾å‡†å¤‡å‡½æ•°

        # é¢„æµ‹
        score, cls, probs = ranker.predict(*features)
        scores.append({
            'symbol': row['symbol'],
            'model_score': score,
            'model_class': cls,
            'prob_0': probs[0],
            'prob_1': probs[1],
            'prob_2': probs[2],
        })

    # ä¿å­˜ç»“æœ
    results = pd.DataFrame(scores)
    results = results.sort_values('model_score', ascending=False)
    results.to_csv(f"data/ranked/ranked_{today}.csv", index=False)

    print(f"âœ“ å®Œæˆæ‰“åˆ†: {len(results)} ä¸ªæ ‡çš„")
    print(f"  Top 5: {results.head(5)['symbol'].tolist()}")

if __name__ == "__main__":
    main()
```

ä¿®æ”¹ `sim_trader.py` è¯»å–æ‰“åˆ†ç»“æœ:

```python
class Trader:
    def select_positions(self):
        today = datetime.now().strftime("%Y%m%d")
        ranked_file = f"data/ranked/ranked_{today}.csv"

        if Path(ranked_file).exists():
            # è¯»å–æ¨¡å‹æ‰“åˆ†ç»“æœ
            ranked = pd.read_csv(ranked_file)
            top_symbols = ranked.head(20)['symbol'].tolist()
        else:
            # é™çº§åˆ°ä¼ ç»Ÿç­–ç•¥
            top_symbols = self.traditional_selection()

        return top_symbols
```

### æ–¹æ¡ˆC: ç»ˆæä¼˜åŒ–ï¼ˆæœ€çœèµ„æºï¼‰

```
æœ¬åœ°: è®­ç»ƒæ¨¡å‹ + å¯¼å‡ºONNX
ECS:
  1. ä½¿ç”¨ONNX Runtimeï¼ˆæ¯”PyTorchå°70%ï¼‰
  2. å®šæ—¶æ‰“åˆ†æ¨¡å¼
  3. äº¤æ˜“ç¨‹åºè¯»å–æ‰“åˆ†ç»“æœ

ä¼˜ç‚¹ï¼š
- å†…å­˜å ç”¨æœ€å°ï¼ˆ~250MBï¼‰
- é€Ÿåº¦å¿«
- æ— éœ€PyTorch

æ­¥éª¤ï¼š
```

åˆ›å»ºONNXå¯¼å‡ºè„šæœ¬:

<function_calls>
<invoke name="Write">
<parameter name="content">#!/usr/bin/env python3
"""
å°†PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼
ONNXæ¨¡å‹æ›´å°ã€æ›´å¿«ã€æ›´çœå†…å­˜
"""
import json
from pathlib import Path

import torch
from scripts.modeling.model import TransformerRanker


def export_to_onnx(model_dir: Path = Path("models")):
    """å¯¼å‡ºæ¨¡å‹ä¸ºONNXæ ¼å¼"""

    # åŠ è½½å…ƒæ•°æ®
    meta_path = model_dir / "rank_model_meta.json"
    with open(meta_path, "r") as f:
        meta = json.load(f)

    # åŠ è½½PyTorchæ¨¡å‹
    model_path = model_dir / "rank_model.pt"
    model = TransformerRanker(**meta["model_kwargs"])
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()

    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    seq_len = meta["seq_len"]
    seq_dim = meta["model_kwargs"]["seq_dim"]
    feature_dim = meta["model_kwargs"]["feature_dim"]

    dummy_sequence = torch.randn(1, seq_len, seq_dim)
    dummy_features = torch.randn(1, feature_dim)

    # å¯¼å‡ºONNX
    onnx_path = model_dir / "rank_model.onnx"
    torch.onnx.export(
        model,
        (dummy_sequence, dummy_features),
        str(onnx_path),
        input_names=["sequence", "features"],
        output_names=["logits"],
        dynamic_axes={
            "sequence": {0: "batch_size"},
            "features": {0: "batch_size"},
            "logits": {0: "batch_size"},
        },
        opset_version=14,
    )

    print(f"âœ“ ONNXæ¨¡å‹å·²å¯¼å‡º: {onnx_path}")

    # éªŒè¯ONNXæ¨¡å‹
    try:
        import onnxruntime as ort
        session = ort.InferenceSession(str(onnx_path))

        # æµ‹è¯•æ¨ç†
        onnx_inputs = {
            "sequence": dummy_sequence.numpy(),
            "features": dummy_features.numpy(),
        }
        onnx_outputs = session.run(None, onnx_inputs)

        # å¯¹æ¯”PyTorchè¾“å‡º
        with torch.no_grad():
            torch_outputs = model(dummy_sequence, dummy_features)

        diff = abs(onnx_outputs[0] - torch_outputs.numpy()).max()
        print(f"âœ“ ONNXéªŒè¯æˆåŠŸï¼Œæœ€å¤§è¯¯å·®: {diff:.6f}")

        # æ–‡ä»¶å¤§å°å¯¹æ¯”
        import os
        pt_size = os.path.getsize(model_path) / 1024**2
        onnx_size = os.path.getsize(onnx_path) / 1024**2
        print(f"\næ–‡ä»¶å¤§å°:")
        print(f"  PyTorch (.pt):  {pt_size:.2f} MB")
        print(f"  ONNX (.onnx):   {onnx_size:.2f} MB")
        print(f"  èŠ‚çœ: {(1 - onnx_size/pt_size) * 100:.1f}%")

    except ImportError:
        print("âš ï¸  æœªå®‰è£…onnxruntimeï¼Œè·³è¿‡éªŒè¯")
        print("   å®‰è£…: pip install onnxruntime")


if __name__ == "__main__":
    export_to_onnx()
